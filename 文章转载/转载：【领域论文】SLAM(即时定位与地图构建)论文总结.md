> 转自：https://zhuanlan.zhihu.com/p/422297314

检索主页：[arxiv.org](https://link.zhihu.com/?target=http%3A//arxiv.org/)

检索关键词：SLAM

检索时间：2021.10.09

**SLAM论文-综述**

从 SLAM 到态势感知：挑战与调查：[https://arxiv.org/abs/2110.00273](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2110.00273)

强大的 SLAM 系统：我们到了吗？：[https://arxiv.org/abs/2109.13160](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2109.13160)

现代开源视觉SLAM方法的比较：[https://arxiv.org/abs/2108.01654](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.01654)

现代通用视觉SLAM方法的比较：[https://arxiv.org/abs/2107.07589](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2107.07589)

传感器、SLAM 和长期自治：回顾：[https://arxiv.org/abs/1807.01605](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1807.01605)

RGB 深度 SLAM 回顾：[https://arxiv.org/abs/1805.07696](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.07696)

SLAM 应用的嵌入式系统架构：[https://arxiv.org/abs/1702.01295](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1702.01295)

SLAM问题感知方法与特征提取算法综述：[https://arxiv.org/abs/1303.3605](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1303.3605)

GSLAM：通用 SLAM 框架和基准：[https://arxiv.org/abs/1902.07995](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1902.07995)

对流行的视觉 SLAM 算法进行基准测试和比较：[https://arxiv.org/abs/1811.09895](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.09895)

结合事件、图像和 IMU 在 HDR 和高速场景中实现稳健的视觉 SLAM：[https://arxiv.org/abs/1709.06310](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1709.06310)

基于关键帧的单目 SLAM：设计、调查和未来方向：[https://arxiv.org/abs/1607.00470](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1607.00470)

**SLAM论文-嵌入式**

eSLAM：FPGA 平台上实时 ORB-SLAM 的节能加速器：[https://arxiv.org/abs/1906.05096](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1906.05096)

一种基于 FPGA 的可扩展架构，用于 SLAM 中的深度估计：[https://arxiv.org/abs/1902.04907](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1902.04907)

基于FPGA的实时视觉SLAM ORB特征提取：[https://arxiv.org/abs/1710.07312](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1710.07312)

SLAM 应用的嵌入式系统架构：[https://arxiv.org/abs/1702.01295](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1702.01295)

**SLAM论文-数据集**

Hilti SLAM 挑战数据集：[https://arxiv.org/abs/2109.11316](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2109.11316)

4Seasons：自动驾驶中多天气SLAM的跨季节数据集：[https://arxiv.org/abs/2009.06364](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2009.06364)

TartanAir：突破视觉 SLAM 极限的数据集：[https://arxiv.org/abs/2003.14338](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.14338)

结合轮速异常检测的单目视觉惯性SLAM算法：[https://arxiv.org/abs/2003.09901](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.09901)

终身 SLAM 的 OpenLORIS-Scene 数据集：[https://arxiv.org/abs/1911.05603](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1911.05603)

事件相机数据集和模拟器：用于姿势估计、视觉里程计和 SLAM 的基于事件的数据：[https://arxiv.org/abs/1610.08336](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1610.08336)

**SLAM论文-相机视觉**

InterpolationSLAM：旋转场景中的新型鲁棒视觉SLAM系统：[https://arxiv.org/abs/2110.02593](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2110.02593)

DROID-SLAM：用于单目、立体和 RGB-D 相机的深度视觉 SLAM：[https://arxiv.org/abs/2108.10869](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.10869)

一种用于自动驾驶的混合稀疏-密集单目SLAM系统：[https://arxiv.org/abs/2108.07736](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.07736)

COVINS：用于集中协作的视觉惯性 SLAM：[https://arxiv.org/abs/2108.05756](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.05756)

具有图形切割优化多平面重建的视觉 SLAM：[https://arxiv.org/abs/2108.04281](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.04281)

用于宽视差重定位的对象增强 RGB-D SLAM：[https://arxiv.org/abs/2108.02522](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.02522)

将学习到的局部和全局嵌入合并到单目视觉 SLAM 中：[https://arxiv.org/abs/2108.02028](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.02028)

在选择性帧上使用语义分割改进实时单目 SLAM：[https://arxiv.org/abs/2105.00114](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2105.00114)

一个几乎全局收敛的视觉 SLAM 观察者，没有持续激励：[https://arxiv.org/abs/2104.02966](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2104.02966)

LIFT-SLAM：一种基于深度学习特征的单目视觉SLAM方法：[https://arxiv.org/abs/2104.00099](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2104.00099)

混合单目视觉SLAM方法学习特征描述符的比较评估：[https://arxiv.org/abs/2104.00085](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2104.00085)

iRotate：面向全向机器人的主动视觉 SLAM：[https://arxiv.org/abs/2103.11641](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2103.11641)

OV2SLAM：用于实时应用的完全在线且多功能的视觉 SLAM：[https://arxiv.org/abs/2102.04060](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.04060)

服务机器人的协作视觉 SLAM 框架：[https://arxiv.org/abs/2102.03228](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.03228)

一种室内动态场景的RGB-D SLAM算法：[https://arxiv.org/abs/2011.14041](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2011.14041)

CamVox：低成本且精确的激光雷达辅助视觉 SLAM 系统：[https://arxiv.org/abs/2011.11357](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2011.11357)

BirdSLAM：鸟瞰中的单目多体SLAM：[https://arxiv.org/abs/2011.07613](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2011.07613)

空城：视觉 SLAM 的动态对象不变空间：[https://arxiv.org/abs/2010.07646](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2010.07646)

DOT：用于视觉 SLAM 的动态对象跟踪：[https://arxiv.org/abs/2010.00052](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2010.00052)

基于线流的 SLAM：[https://arxiv.org/abs/2009.09972](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2009.09972)

PL-VINS：具有点和线特征的实时单目视觉惯性 SLAM：[https://arxiv.org/abs/2009.07462](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2009.07462)

Attention-SLAM：从人类凝视中学习的视觉单目 SLAM：[https://arxiv.org/abs/2009.06886](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2009.06886)

FastORB-SLAM：具有描述符独立关键点匹配的快速 ORB-SLAM 方法：[https://arxiv.org/abs/2008.09870](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.09870)

基于相交线的立体平面SLAM：[https://arxiv.org/abs/2008.08218](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.08218)

DXSLAM：具有深度特征的强大且高效的视觉 SLAM 系统：[https://arxiv.org/abs/2008.05416](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.05416)

Structure-SLAM：室内环境中的低漂移单目SLAM：[https://arxiv.org/abs/2008.01963](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.01963)

视觉惯性 SLAM 的深度深度估计：[https://arxiv.org/abs/2008.00092](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.00092)

用于视觉 SLAM 的动态对象跟踪和掩蔽：[https://arxiv.org/abs/2008.00072](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.00072)

ORB-SLAM3：用于视觉、视觉惯性和多地图 SLAM 的准确开源库：[https://arxiv.org/abs/2007.11898](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2007.11898)

AVP-SLAM：停车场自动驾驶车辆的语义视觉映射和定位：[https://arxiv.org/abs/2007.01813](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2007.01813)

DeepRelativeFusion：使用单图像相对深度预测的密集单目 SLAM：[https://arxiv.org/abs/2006.04047](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.04047)

VIR-SLAM：用于单机器人和多机器人系统的视觉、惯性和测距 SLAM：[https://arxiv.org/abs/2006.00420](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.00420)

VDO-SLAM：视觉动态对象感知 SLAM 系统：[https://arxiv.org/abs/2005.11052](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2005.11052)

用于自动驾驶汽车视觉定位的持久地图保存：ORB-SLAM 扩展：[https://arxiv.org/abs/2005.07429](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2005.07429)

EAO-SLAM：基于集成数据关联的单目半密集目标SLAM：[https://arxiv.org/abs/2004.12730](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2004.12730)

用于自改进单目SLAM和深度预测的伪RGB-D：[https://arxiv.org/abs/2004.10681](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2004.10681)

FlowFusion：基于光流的动态密集RGB-D SLAM：[https://arxiv.org/abs/2003.05102](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.05102)

StereoNeuroBayesSLAM：一种基于直接稀疏方法的受神经生物学启发的立体视觉SLAM系统：[https://arxiv.org/abs/2003.03091](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.03091)

用于视觉 SLAM 的体素图：[https://arxiv.org/abs/2003.02247](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.02247)

为任意多相机系统重新设计 SLAM：[https://arxiv.org/abs/2003.02014](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.02014)

用于动态环境的多目标单目 SLAM：[https://arxiv.org/abs/2002.03528](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2002.03528)

RGB-D 里程计和 SLAM：[https://arxiv.org/abs/2001.06875](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2001.06875)

DeepFactors：实时概率密集单目 SLAM：[https://arxiv.org/abs/2001.05049](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2001.05049)

基于训练轨迹的自动泊车系统在环视摄像头上使用视觉 SLAM：[https://arxiv.org/abs/2001.02161](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2001.02161)

用于大规模室外环境的具有地标的视觉语义 SLAM：[https://arxiv.org/abs/2001.01028](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2001.01028)

在单帧上训练深度 SLAM：[https://arxiv.org/abs/1912.05405](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1912.05405)

基于非参数联合几何和外观表示的 RGB-D 相机的基于关键帧的连续视觉 SLAM：[https://arxiv.org/abs/1912.01064](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1912.01064)

A*SLAM：双鱼眼立体边缘 SLAM：[https://arxiv.org/abs/1911.04063](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1911.04063)

OpenVSLAM：多功能视觉 SLAM 框架：[https://arxiv.org/abs/1910.01122](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1910.01122)

TagSLAM：具有基准标记的鲁棒 SLAM：[https://arxiv.org/abs/1910.00679](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1910.00679)

SE-SLAM：半密集结构化基于边缘的单目SLAM：[https://arxiv.org/abs/1909.03917](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1909.03917)

Deep-SLAM++：基于类特定深度形状先验的对象级RGBD SLAM：[https://arxiv.org/abs/1907.09691](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1907.09691)

DetectFusion：在实时 SLAM 中检测和分割已知和未知动态对象：[https://arxiv.org/abs/1907.09127](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1907.09127)

用于 3D 视觉惯性 SLAM 的高效 Schmidt-EKF：[https://arxiv.org/abs/1903.08636](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1903.08636)

HE-SLAM：基于直方图均衡化和 ORB 特征的立体 SLAM 系统：[https://arxiv.org/abs/1902.03365](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1902.03365)

GEN-SLAM：单目同时定位和映射的生成建模：[https://arxiv.org/abs/1902.02086](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1902.02086)

基于无监督学习的深度估计辅助视觉 SLAM 方法：[https://arxiv.org/abs/1901.07288](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1901.07288)

DF-SLAM：一种基于深度局部特征的深度学习增强型视觉SLAM系统：[https://arxiv.org/abs/1901.07223](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1901.07223)

Edge SLAM：基于边缘点的单目视觉SLAM：[https://arxiv.org/abs/1901.04210](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1901.04210)

MID-Fusion：基于八叉树的对象级多实例动态SLAM：[https://arxiv.org/abs/1812.07976](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1812.07976)

Fusion++：体积对象级 SLAM：[https://arxiv.org/abs/1808.08378](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1808.08378)

SLAMBench2：用于视觉 SLAM 的多目标头对头基准测试：[https://arxiv.org/abs/1808.06820](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1808.06820)

松耦合半直接单目SLAM：[https://arxiv.org/abs/1807.10073](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1807.10073)

用于准确实时定位和 3D 映射的 RGBiD-SLAM：[https://arxiv.org/abs/1807.08271](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1807.08271)

基于子图的姿态图视觉 SLAM：一个强大的视觉探索和定位系统：[https://arxiv.org/abs/1807.01012](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1807.01012)

CubeSLAM：单目3D对象SLAM：[https://arxiv.org/abs/1806.00557](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1806.00557)

使用车轮和 MEMS 陀螺仪的紧耦合单目视觉里程计 SLAM：[https://arxiv.org/abs/1804.04854](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1804.04854)

单目视觉惯性 SLAM 的重定位、全局优化和地图合并：[https://arxiv.org/abs/1803.01549](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1803.01549)

带有 RGB-D 相机的稳健的基于关键帧的密集 SLAM：[https://arxiv.org/abs/1711.05166](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1711.05166)

PIRVS：具有灵活传感器融合和硬件协同设计的高级视觉惯性 SLAM 系统：[https://arxiv.org/abs/1710.00893](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1710.00893)

ProSLAM：从程序员的角度绘制 SLAM：[https://arxiv.org/abs/1709.04377](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1709.04377)

GSLAM：通过 Global Structure-from-Motion 实现初始化稳健的单目视觉 SLAM：[https://arxiv.org/abs/1708.04814](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1708.04814)

CNN-SLAM：具有学习深度预测的实时密集单目 SLAM：[https://arxiv.org/abs/1704.03489](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1704.03489)

实时单目物体 SLAM：[https://arxiv.org/abs/1504.02398](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1504.02398)

ORB-SLAM：多功能准确的单目SLAM系统：[https://arxiv.org/abs/1502.00956](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1502.00956)

**SLAM论文-激光雷达**

ART-SLAM：准确的实时 6DoF LiDAR SLAM：[https://arxiv.org/abs/2109.05483](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2109.05483)

用于 3D LiDAR SLAM 的实时全局重新定位框架：[https://arxiv.org/abs/2109.00200](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2109.00200)

DSP-SLAM：具有深度形状先验的面向对象的 SLAM：[https://arxiv.org/abs/2108.09481](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.09481)

激光雷达强度图像对 3D SLAM 中基于分段的环路闭合的描述能力：[https://arxiv.org/abs/2108.01383](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.01383)

基于光栅化 LIDAR 图像的自适应局部地图的终身 SLAM 方法：[https://arxiv.org/abs/2107.07133](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2107.07133)

SA-LOAM：具有循环闭合的语义辅助激光雷达 SLAM：[https://arxiv.org/abs/2106.11516](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2106.11516)

OverlapNet：基于 LiDAR 的 SLAM 的闭环：[https://arxiv.org/abs/2105.11344](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2105.11344)

基于训练数据自动生成的动态物体感知激光雷达SLAM：[https://arxiv.org/abs/2104.03657](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2104.03657)

基于贪婪的高效 LiDAR SLAM 特征选择：[https://arxiv.org/abs/2103.13090](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2103.13090)

使用来自 3D LIDAR 点云光栅化图像的 ORB 特征的基于 6-DOF 特征的 LIDAR SLAM：[https://arxiv.org/abs/2103.10678](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2103.10678)

LCDNet：用于激光雷达 SLAM 的深环闭合检测和点云配准：[https://arxiv.org/abs/2103.05056](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2103.05056)

Ground-SLAM：用于结构化多层环境的地面约束 LiDAR SLAM：[https://arxiv.org/abs/2103.03713](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2103.03713)

LiTAMIN2：基于超轻 LiDAR 的 SLAM，使用几何近似和 KL-Divergence：[https://arxiv.org/abs/2103.00784](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2103.00784)

基于特征重识别的精确视觉惯性 SLAM：[https://arxiv.org/abs/2102.13438](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.13438)

MULLS：通过多度量线性最小二乘法实现多功能 LiDAR SLAM：[https://arxiv.org/abs/2102.03771](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.03771)

自然环境中的在线鲁棒滑动窗口 LiDAR SLAM：[https://arxiv.org/abs/2101.06615](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2101.06615)

具有分层掩蔽和运动状态分类的立体相机视觉 SLAM：[https://arxiv.org/abs/2101.06563](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2101.06563)

GP-SLAM+：基于改进区域化高斯过程图重建的实时3D激光雷达SLAM：[https://arxiv.org/abs/2008.00644](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.00644)

用于基于 3D 激光雷达的在线制图的高效连续时间 SLAM：[https://arxiv.org/abs/1810.06802](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1810.06802)

实时单目对象模型感知稀疏 SLAM：[https://arxiv.org/abs/1809.09149](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1809.09149)

ORB-SLAM2：用于单目、立体和 RGB-D 相机的开源 SLAM 系统：[https://arxiv.org/abs/1610.06475](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1610.06475)

RFM-SLAM：利用相对特征测量来分离 SLAM 中的方向和位置估计：[https://arxiv.org/abs/1609.05235](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1609.05235)

**SLAM论文-毫米波雷达**

具有移动散射体的协同毫米波 PHD-SLAM：[https://arxiv.org/abs/2106.11515](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2106.11515)

雷达 SLAM：适用于所有天气条件的强大 SLAM 系统：[https://arxiv.org/abs/2104.05347](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2104.05347)

RadarSLAM：全天候基于雷达的大规模 SLAM：[https://arxiv.org/abs/2005.02198](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2005.02198)

**SLAM论文-融合**

AcousticFusion：在动态环境中将声源定位与视觉 SLAM 融合：[https://arxiv.org/abs/2108.01246](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.01246)

多部智能手机协同视觉惯性SLAM：[https://arxiv.org/abs/2106.12186](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2106.12186)

Lvio-Fusion：使用Actor-critic方法的自适应多传感器融合SLAM框架：[https://arxiv.org/abs/2106.06783](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2106.06783)

VIRAL SLAM：紧耦合相机-IMU-UWB-Lidar SLAM：[https://arxiv.org/abs/2105.03296](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2105.03296)

具有回环和全局优化的全景环形 SLAM：[https://arxiv.org/abs/2102.13400](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.13400)

Pepper机器人的混合SLAM和物体识别系统：[https://arxiv.org/abs/1903.00675](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1903.00675)

UWB/LiDAR 融合用于协作仅距离 SLAM：[https://arxiv.org/abs/1811.02854](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.02854)

MultiCol-SLAM - 模块化实时多相机 SLAM 系统：[https://arxiv.org/abs/1610.07336](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1610.07336)

基于对象的 SLAM 的多模态跟踪：[https://arxiv.org/abs/1603.04117](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1603.04117)

**SLAM论文-语义**

Kimera-Multi：适用于多机器人系统的稳健、分布式、密集的度量语义 SLAM：[https://arxiv.org/abs/2106.14386](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2106.14386)

SuMa++：基于激光雷达的高效语义SLAM：[https://arxiv.org/abs/2105.11320](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2105.11320)

具有独立旋转相机的主动视觉 SLAM：[https://arxiv.org/abs/2105.08958](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2105.08958)

动态环境中的实时语义RGB-D SLAM：[https://arxiv.org/abs/2104.01316](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2104.01316)

DS-SLAM：面向动态环境的语义视觉SLAM：[https://arxiv.org/abs/1809.08379](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1809.08379)

**SLAM论文-方法**

在无线通信系统中实现即插即用和众包 SLAM：[https://arxiv.org/abs/2108.03609](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2108.03609)

可微 SLAM-net：用于视觉导航的学习粒子 SLAM：[https://arxiv.org/abs/2105.07593](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2105.07593)

我以前来过这里吗？学习在基于图的 SLAM 中使用 LiDAR 数据关闭循环：[https://arxiv.org/abs/2103.06713](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2103.06713)

Kimera：从 SLAM 到具有 3D 动态场景图的空间感知：[https://arxiv.org/abs/2101.06894](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2101.06894)

异步多视图SLAM：[https://arxiv.org/abs/2101.06562](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2101.06562)

视觉SLAM方法在不同环境下的稳健性评估：[https://arxiv.org/abs/2009.05427](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2009.05427)

一种使用低成本 LiDAR 实现高性能 LiDAR SLAM 的方法：[https://arxiv.org/abs/2008.03694](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2008.03694)

即插即用 SLAM：模块化和易用性的统一 SLAM 架构：[https://arxiv.org/abs/2003.00754](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.00754)

动态 SLAM：对速度的需求：[https://arxiv.org/abs/2002.08584](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2002.08584)

解析SLAM的数值和实验实现：[https://arxiv.org/abs/1911.05177](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1911.05177)

使用合成数据估计单目 SLAM 中的绝对尺度：[https://arxiv.org/abs/1909.00713](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1909.00713)

对象级语义 SLAM 的稳健数据关联：[https://arxiv.org/abs/1909.13493](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1909.13493)

重新思考 SLAM 的轨迹评估：一种概率的、连续时间的方法：[https://arxiv.org/abs/1906.03996](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1906.03996)

EM-Fusion：具有概率数据关联的动态对象级 SLAM：[https://arxiv.org/abs/1904.11781](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1904.11781)

视觉 SLAM：为什么要 Bundle Adjust？：[https://arxiv.org/abs/1902.03747](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1902.03747)

SLAM和语义分割相互改进的统一框架：[https://arxiv.org/abs/1812.10016](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1812.10016)

PCR-Pro：姿态图SLAM的3D稀疏和不同尺度点云配准和信息矩阵的鲁棒估计：[https://arxiv.org/abs/1808.09693](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1808.09693)

基于通用目标检测的单目SLAM贝叶斯尺度估计校正尺度漂移：[https://arxiv.org/abs/1711.02768](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1711.02768)

2D SLAM质量评估方法：[https://arxiv.org/abs/1708.02354](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1708.02354)

走向几何深度 SLAM：[https://arxiv.org/abs/1707.07410](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1707.07410)

差分几何SLAM：[https://arxiv.org/abs/1506.00547](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1506.00547)

介绍 SLAMBench，一种 SLAM 的性能和准确性基准测试方法：[https://arxiv.org/abs/1410.2167](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1410.2167)